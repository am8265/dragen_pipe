The model in https://github.com/igm-team/dragen_pipe/tree/master/automated_ethnicity_relatedness/data is the same as in /nfs/goldstein/software/dragen_pipe/master/automated_ethnicity_relatedness/data

model: 37MB_markers_model.obj
markers: filtered.37MB.master.training.map
Code: model_ancestry.py, helper_functions.py (predict, train, tune etc)


The trained, tuned model is as follows:
>>> import cPickle as pickle
>>> f = open('data/37MB_markers_model.obj','rb')
>>> model = pickle.load(f)
>>> model
Pipeline(steps=[('scaling', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('nnet', MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',
       beta_1=0.9...      solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,
       warm_start=False))])

>>> model.steps[2][1]
MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',
       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(6,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,
       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,
       warm_start=False)

The ith element in the coefs list represents the weight matrix corresponding to layer i
>>> model.steps[2][1].coefs_ 
[array([[-5.59176605,  0.19690849,  0.13455022,  1.7519941 , -2.31049899,
        -1.70689856],
       [-4.5654157 , -0.02212472,  1.21029041, -0.12719672,  0.25874555,
        -4.58967194],
       [-2.41409765,  0.17823914, -0.84970289, -1.20605152, -2.2492001 ,
         4.1604556 ],
       [-3.65626385,  0.04724224,  0.0864585 ,  2.22323358,  5.162491  ,
        -2.45961785],
       [-1.63150876, -0.15803884, -1.79075103,  2.2325059 , -4.80199605,
         0.76493476],
       [-1.39546601,  0.14321917, -2.07708777,  0.36625699, -6.20183385,
         1.01701626]]), array([[  6.6496609 ,   3.29630872,  -2.00797605,  -4.00751956,
         -0.78685552,  -3.60528544],
       [-10.49809428,  -2.04442901,   6.56292899,   3.96003658,
         -0.36106289,   2.1996509 ],
       [ -8.29049011,  -3.2748813 ,  -0.64824742,   6.36184682,
          1.28908282,   3.7358498 ],
       [ -3.55363252,   2.85431047,  -3.11386894,  -9.48879709,
          4.53467355,   7.64804346],
       [  4.98120554,  -2.20750991,  -3.53844739,   1.72163362,
          7.40737581,  -8.12155773],
       [  3.93943625,   3.10694028,   5.49046483,  -6.0853091 ,
         -3.5021731 ,  -3.1428167 ]])]

The ith element in the intercepts list represents the bias vector corresponding to layer i + 1.
>>> model.steps[2][1].intercepts_
[array([ 0.04324262,  1.37268838,  0.47737087, -0.00146364, -0.47800338,
        0.22920901]), array([ 3.13093887,  0.06160075,  0.13151712,  1.9346205 , -4.11007639,
       -2.04369854])]

Since I went through the code, I thought I'd write out a brief description:


Step 1: Create ped
Requires a) realn.recal.bam and analysisReady annocated vcf
         b)    markers map file filtered.37MB.master.training.map    

"create_ped_map.py" (return_pedmap function)     
1. Iterate through each chrom_pos in the marker map file:
    If site is not in vcf:
        //get coverage from bam (ignoring qual, flags)
        if bam_coverage < 10:
            //label as missing
            ped_file_entry: (0,0) 
         else:
            code = 0 
            ped_file_entry: (ref,ref)
        map_file_entry: (chrom,id_var,'0',pos) 

    else:
        if multi-allelic / indel / MNP / invalid_snv:
            // label as missing
            ped_file_entry: (0,0)
            map_file_entry: (chrom,id_var,'0',pos)  (from vcf)
        else:
            ped_file_entry = (ref,ref), (ref,alt) or (alt,alt) depending on whether genotype is (0/0, [(0/1) or (1/0)] or 1/1 )
            map_file_entry = (chrom,id_var,'0',pos)  (from vcf)

output: ped, map and geno files as follows:

ped_file: family_id    sample_id    0    0    sex    pheno    ped_file_entry1    ped_file_entry2......
map_file: (chrom,id_var,'0',pos) (1 line for each)

log the number of "missing" labels

Step 2: Use helper_functions.py predict_new_samples function and the trained model described above
1. Convert ped obtained in Step 1 -> geno encoding
    a) get positions from map file and corresponding reference allele from fasta
    b) for each ped file entry:
            if allele == ref:
                //encode 0

            if allele == 0:
                //encode 9

            else:
                keep count of allele != ref (will be 1 in case of ref-alt/ alt-ref or 2 in case of alt-alt)

    c)    count the fraction of encode = 9. 1-this_fraction is the  "genotyping_rate" in the     dragen_qc_metrics table.

    replace "encode 9" with "0" 

    using the trained model, and the encoding vector above, get the prediction probability for each ethnicity class and insert it into dragen_qc_metrics.

NOTE: The maximum number of samples for which it can predict ethnicity at a time is 10k. (hard-coded)


###############################

TO RUN OUTSIDE OF PIPELINE:

Requirements - Need to install the following:

For create ped:
pysam
/nfs/goldstein/software/python2.7.7/lib/python2.7/site-packages/pysam
pyfaidx
/nfs/goldstein/software/python2.7.7/lib/python2.7/site-packages/pyfaidx
python2.7.7
/nfs/goldstein/software/python2.7.7/bin/python2.7
file: /scratch/HS_Build37/BWA_INDEX_hs37d5/hs37d5.fa
marker file: /nfs/goldstein/software/dragen_pipe/master/automated_ethnicity_relatedness/data/filtered.37MB.master.training.map

For running the predict_new_samples code:
numpy
/nfs/goldstein/software/python2.7.7/lib/python2.7/site-packages/numpy
allel (for hyperparameter tuning, not required here, can comment it out if you dont want to install allel)
/nfs/goldstein/software/python2.7.7/lib/python2.7/site-packages/allel
sklearn
/nfs/goldstein/software/python2.7.7/lib/python2.7/site-packages/sklearn



Create_ped_command: 

usage: Create a ped file from a vcf file and a bam file [-h] --sample_id
                                                        SAMPLE_ID
                                                        [--family_id FAMILY_ID]
                                                        --vcf VCF --markers
                                                        MARKERS [--sex {M,F}]
                                                        [--pheno {1,2}] --bam
                                                        BAM --seqtype SEQ
                                                        --pseudo_prepid
                                                        PSEUDO_PREPID --outdir
                                                        OUT --stem STEM
                                                        [--ref REF_FASTA]
                                                        [--logfile LOG_FILE]

Takes as input : 1. A valid vcf file 2. Marker loci Output : A ped file
containing genotype information at the appropriate marker loci

optional arguments:
  -h, --help            show this help message and exit
  --sample_id SAMPLE_ID, -sample_id SAMPLE_ID
                        CHGVID (default: None)
  --family_id FAMILY_ID, -family_id FAMILY_ID
                        The family id (if not given then we use the sample_id
                        as the family id) (default: dummy)
  --vcf VCF, -vcf VCF   The input vcf (default: None)
  --markers MARKERS, -markers MARKERS
                        The input genetic loci, the file should adhere to the
                        plink map format : http://pngu.mgh.harvard.edu/~purcel
                        l/plink/data.shtml#map In short there should be
                        exactly 4 columns : 1.Chromosome 2.Snp identifier
                        3.Genetic distance 4.Base-pair position (bp units) For
                        this program it is enough if you have the 1st and 4th
                        column filed in correctly, just fill in the other 2
                        columns with dummy data if you do not have that
                        information (default: None)
  --sex {M,F}, -sex {M,F}
                        M/F (default: M)
  --pheno {1,2}, -pheno {1,2}
                        1/2 (default: 1)
  --bam BAM, -bam BAM   Path to the bam file (default: None)
  --seqtype SEQ, -seq SEQ
                        The type of sequencing, i.e. Exome or Genome (default:
                        None)
  --pseudo_prepid PSEUDO_PREPID, -pseudo_prepid PSEUDO_PREPID
                        The prepid for your sample (default: None)
  --outdir OUT, -out OUT
                        Output dir, can give full path, output directories
                        will be created if it doesnt exist (default: None)
  --stem STEM, -stem STEM
                        The stem for the output file, a .ped and .map will be
                        appended to this for the output files (default: None)
  --ref REF_FASTA, -ref REF_FASTA
                        The reference genome (default:
                        /scratch/HS_Build37/BWA_INDEX_hs37d5/hs37d5.fa)
  --logfile LOG_FILE, -log LOG_FILE
                        The full path to the logfile (default: log.txt)

The ones with default = NULL are the mandatory arguments
                        
Example:
Create ped                      
python2.7 create_ped_map.py --sample_id wcarpAUT001722Ao1 --family_id AUT0017 --vcf /nfs/seqscratch_ssd/ALIGNMENT/BUILD37/DRAGEN/EXOME/wcarpAUT001722Ao1.98517/wcarpAUT001722Ao1.98517.analysisReady.vcf.gz --markers /nfs/goldstein/software/dragen_pipe/master/automated_ethnicity_relatedness/data/filtered.37MB.master.training.map --sex M --bam /nfs/seqscratch_ssd/ALIGNMENT/BUILD37/DRAGEN/EXOME/wcarpAUT001722Ao1.98517/wcarpAUT001722Ao1.98517.realn.recal.bam --seqtype Exome --pseudo_prepid 98517 --outdir /nfs/seqscratch10/mml2204/TEST_eth --stem out --ref /scratch/HS_Build37/BWA_INDEX_hs37d5/hs37d5.fa


Model ancestry:
python2.7 "model_ancestry.py" --testing-ped /nfs/seqscratch10/mml2204/TEST_eth/out.ped --mapfile /nfs/goldstein/software/dragen_pipe/master/automated_ethnicity_relatedness/data/filtered.37MB.master.training.map  --reference /scratch/HS_Build37/BWA_INDEX_hs37d5/hs37d5.fa --output-prob-file /nfs/seqscratch10/mml2204/TEST_eth/out_prob  --input-model /nfs/goldstein/software/dragen_pipe/master/automated_ethnicity_relatedness/data/37MB_markers_model.obj


